{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network In-Class Exercises\n",
    "\n",
    "These are the in-class exercises accompanying the Neural networks unit.  Do these exercises as you progress through the sections in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Consider a neural network where, for each scalar input `x`, it outputs a predicted value `yhat` as follows:\n",
    "\n",
    "    zh = wh*x + bh\n",
    "    uh = 1/(1 + exp(-zh))   # Sigmoid activation\n",
    "    zo = uh.dot(wo) + bo\n",
    "    yhat = zo               # No activation\n",
    "\n",
    "Using the parameter values below, for scalar inputs `x` in the range of -4 to 8:\n",
    "\n",
    "*  Plot `uh` vs `x`.  Since there are three hidden units, your graph should have three curves\n",
    "*  Plot `yhat` vs `x`.  Since there is one output unit, your graph should have one curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4,8,100)\n",
    "wh = np.array([1,1,1])\n",
    "bh = -np.array([0,2,4])\n",
    "wo = np.array([1,-2,0.5])\n",
    "bo = 0.1\n",
    "\n",
    "# TODO\n",
    "#   uh = ...\n",
    "#   yhat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "We will now try to a similar neural network to fit a simple nonlinear function. Suppose that we are trying to learn a scalar relation:\n",
    "\n",
    "    y = f0(x)\n",
    "    \n",
    "where `x` and `y` are scalars. Suppose that the true function is `f0(x) = sin(2*pi*x)`, but the estimator does not know this. We get training data as follows.  First plot the training data `xtr`, `ytr`, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr = 100\n",
    "xtr = np.random.rand(ntr)\n",
    "ytr = np.sin(2*np.pi*xtr) + np.random.normal(0,0.1,ntr)\n",
    "\n",
    "# TODO\n",
    "# plt.plot(...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn the function, consider a neural network with the same structure as before:\n",
    "\n",
    "    zh = wh*x + bh\n",
    "    uh = 1/(1 + exp(-zh))   # Sigmoid activation\n",
    "    yhat = uh.dot(wo) + bo  # No activation\n",
    "    \n",
    "As we progress through the unit, we will show how to fit the parameters for the network in both the hidden and output layers.  But, to give you an idea of the training, in this exercise, we will fit just the output weights and biases, `wh` and `bh`,  with the hidden weights and biases, `wo` and `bo`, fixed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given parameters in the hidden layer, complete the function `hidden()` below that maps a vector of inputs `x` to produce the matrix of hidden outputs `uh`.  Compute the value of `uh_tr = hidden(xtr,wh,bh)` which is the value of the hidden unit outputs on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhid = 4\n",
    "wh = np.ones(nhid)\n",
    "bh = -np.linspace(0,1,nhid)\n",
    "\n",
    "def hidden(x,wh,bh):\n",
    "    # TODO\n",
    "    return uh\n",
    "\n",
    "# TODO\n",
    "#   uh_tr = hidden(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the parameters for the output layer, we want to find the weights and biases, `wo` and `bo`, such that\n",
    "\n",
    "    ytr ~= uh_tr.dot(wo) + bo\n",
    "\n",
    "We can do this with linear regression:\n",
    "\n",
    "*  Create a `LinearRegression` object `reg`.  \n",
    "*  Fit a linear model with `uh_tr` and `ytr`.  \n",
    "*  Get the coefficients `wo` and `bo` from `reg.coef_` and `reg.intercept_`\n",
    "*  Plot the predictions of the model on `xts` given below.  On the same plot, plot the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Test points\n",
    "xts      = np.linspace(0,1,100)\n",
    "yts_true = np.sin(2*np.pi*xts)  # f0(xts)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:  Training a Neural Network\n",
    "\n",
    "Now we will try to train the neural network using tensorflow.   In the above example, I manually selected the hidden weights so that you can get a good fit.  But, when you have to train both the hidden and output weights, you will need a few more hidden units.  Train a neural network as follows:\n",
    "\n",
    "* Clear the keras session\n",
    "* Create a neural network with 32 hidden units, 1 output unit\n",
    "* Use a sigmoid activation for the hidden layer and a `none` activation for the output layer\n",
    "* Compile with `mean_squared_error` for the `loss` and `metrics`\n",
    "* Fit the model.  You may need to play with the learning rate `lr` and you will probably need many `epochs`.\n",
    "* Plot the predicted and true function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
