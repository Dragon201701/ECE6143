{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA In-Class Exercises\n",
    "\n",
    "Exercises accompanying the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:  Computing PCs Manually on a Synthetic Dataset\n",
    "\n",
    "We begin by showing how to compute and visualize PCs manually on a simple 2-dim synthentic data set.  First, run the following code to generate 100 samples of synthetic data.  Each data point has `d=2` dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "std = 0.2\n",
    "s = np.array([2,1])\n",
    "d = 2\n",
    "ns = 100\n",
    "\n",
    "U = np.random.normal(0,std,(ns,d))\n",
    "v = np.random.uniform(0,1,ns)\n",
    "X = U + (v < p)[:,None]*s[None,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scatter plot of the data of the two features of the data, `X[:,0]` and `X[:,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now manually compute the first principal component.  Later, we will find a faster way using an SVD.\n",
    "\n",
    "*  Compute `xm` the mean of each of the two features.\n",
    "*  Compute `Xm`, the matrix of data samples with the means removed\n",
    "*  Compute the covariance matrix `Q = (1/ns)*Xm.T.dot(Xm)`\n",
    "*  Compute the eigenvalues `lam` and eigenvectors `V` of `Q` using the `np.linalg.eigh(Q)` command.\n",
    "*  Set `v0` be the eigenvector corresponding to the largest eigenvalue.  This is is the first PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   xm = ...\n",
    "#   Q = ...\n",
    "#   lam, V = ...\n",
    "#   v0 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the projection of the data vectors onto the first PC with the following:\n",
    "    \n",
    "    z[i] = Xm[i,:].dot(v0)\n",
    "    Xhat[i,:] = xm + v0*z[i]\n",
    "    \n",
    "Note that we remove the mean when projecting and then add it back.\n",
    "Create a scatter plot with:\n",
    "\n",
    "*  The original data points `X[:,0], X[:,1]` in one color\n",
    "*  The projected data points `Xhat[:,0], Xhat[:,1]` in a second color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   z = ...\n",
    "#   Xhat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:  Computing the Approximation Error\n",
    "\n",
    "We now verify the approximation errors.  For each `k`:\n",
    "\n",
    "*  Compute `Z`, the PC coefficients of `X` \n",
    "*  Compute `Xhat`, the PC approximation of `X` using `k` PC coefficients\n",
    "*  Compute the approximation error, `err[k]` the average error `1/ns sum_{ij} (X[i,j]-Xhat[i,j])**2)`\n",
    "*  Compute the expected approximation error, `err_pred[k]` the expected approximation error based on the eigenvalues `lam`.\n",
    "\n",
    "Remember you will need to sort the eigenvalues in descending order.  You can use the command\n",
    "\n",
    "     I = np.argsort(lam)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the eigenvalues in descending order\n",
    "#   I = np.argsort(lam)[::-1]\n",
    "\n",
    "# TODO\n",
    "#   err = ...\n",
    "#   err_pred = ...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:  Computing the PCA via the SVD\n",
    "\n",
    "*  Compute the matrix `A = 1/np.sqrt(ns)*Xm`\n",
    "*  Compute the economy SVD of `A` with the `np.linalg.svd()` command.  Use `full_matrices=False` option.  Print the dimensions of the components of the SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   A = ...\n",
    "#   U, s, Vtr = np.linalg.svd(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the singular values squared `s**2` match the eigenvalues of the covariance matrix `Q`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the coefficients, `Zhat` of `X` on the PC vectors.  Make sure they match `Z` computed above (up to some sign and permutations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   Zhat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
